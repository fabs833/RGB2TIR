So far, we only get decent test data results if we have very similar training data. None of the models are very robust to any kind of significant change in environment. And, I am skeptical of others showing off results out there. We haven't seen anyone else out there clearly showing they used significantly different test images from their training images. 
Or, in some cases, maybe even just showed off training data. I'll be happy to stand corrected if someone posts indicative training and test data with their results.
Working with dropout didn't seem to have a significant impact. However, the results of the trained ResNet model look promising to me. I think this direction is definitely worth further investigation.
The supercomputer did not like any of the zip files made on my Windows machine. After some frustration, I finally copied the original uncompressed folders on a physical drive, compressed them on an old 2017 iMac I keep around for strange moments like this, and then uploaded them to the supercomputer from there. 
Runtime for 100Epochs on the dataset with ≈29,000+ image pairs (of those 80%, so ≈23,200 image pairs were processed for training) was 10h 41min. on a single node with 4 Nvidia H100 GPU. So, ≈5,800 image pairs x 100 Epochs per GPU over 38,460sec ≈ 0.0663sec per image pair per Epoch on an H100. 
As to the image capture, with The Seek Mosaic sensor and the Arducam Lens Board OV5647 Sensor on the RPi4 recording straight to the Micro SD card, power consumption was ≈1.48Wh for capturing 2000 images over about 2500 seconds. So, even on a very small powerpack with only 10Wh or so, one could easily capture 10,000+ pictures without interruption. For working with a drone the maximum flight time would likely be the limiting factor.
Even without external ventilation or even passive cooling in a closed box, the RPi4 wouldn't overheat, Although, I have never tried it on a really hot day, or with the camera/case exposed to the sun for any prolonged period of time.
